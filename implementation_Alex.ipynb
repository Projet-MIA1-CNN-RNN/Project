{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation des masques 2D et 1D pour les convolutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2D(nn.Conv2d):\n",
    "\tdef __init__(self,mask_type, *args, **kwargs):\n",
    "\t\tsuper(MaskedConv2D, self).__init__()\n",
    "\t\tself.mask_type = mask_type\n",
    "\t\tassert mask_type in ['A', 'B'], \"Unknown Mask Type\"\n",
    "\t\tself.register_buffer('mask', self.weight.data.clone())\n",
    "\t\t_, depth, height, width = self.weight.size()\n",
    "\t\tself.mask.fill_(1)\n",
    "\t\tif mask_type =='A':\n",
    "\t\t\tself.mask[:,:,height//2,width//2:] = 0\n",
    "\t\t\tself.mask[:,:,height//2+1:,:] = 0\n",
    "\t\telse:\n",
    "\t\t\tself.mask[:,:,height//2,width//2+1:] = 0\n",
    "\t\t\tself.mask[:,:,height//2+1:,:] = 0\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tself.weight.data*=self.mask\n",
    "\t\treturn super(MaskedConv2D, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv1d(nn.Conv1d):\n",
    "    def __init__(self, *args, mask='B', **kargs):\n",
    "        super(MaskedConv1d, self).__init__(*args, **kargs)\n",
    "        assert mask in {'A', 'B'}\n",
    "        self.mask_type = mask\n",
    "        self.register_buffer('mask', self.weight.data.clone())\n",
    "        self.mask.fill_(1)\n",
    "    \n",
    "        _, _, W = self.mask.size()\n",
    "    \n",
    "        self.mask[:, :, W//2 + (self.mask_type == 'B'):] = 0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv1d, self).forward(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition de la classe PixelCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "\tdef __init__(self, nb_layer_block=8, channels=64, device=None):\n",
    "\t\tsuper(PixelCNN, self).__init__()\n",
    "\t\tself.nb_block = nb_layer_block\n",
    "\t\tself.channels = channels\n",
    "\t\tself.layers = {}\n",
    "\t\tself.device = device\n",
    "\t\t#first convolution (cf TABLE 1)\n",
    "\t\tself.ConvA = nn.Sequential(\n",
    "\t\t\tMaskedConv2D('A',3, 2*channels, kernel_size=7, bias=False),\n",
    "\t\t\tnn.ReLU(True)\n",
    "\t\t)\n",
    "\t\t#Residual blocks for PixelCNN (figure 5)\n",
    "\t\tself.multiple_blocks = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(2*channels,channels, kernel_size = 1, bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tMaskedConv2D('B',channels,channels, kernel_size = 3, bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.Conv2d(channels,2*channels, kernel_size = 1, bias=False),\n",
    "\t\t\tnn.ReLU(True)\n",
    "\t\t)\n",
    "\t\t#finalisation\n",
    "\t\tself.end = nn.Sequential(\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tMaskedConv2D('B',2*channels, 2 * channels, kernel_size = 1, bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tMaskedConv2D('B',2* channels,2 * channels, kernel_size = 1, bias=False),\n",
    "\t\t\tnn.Conv2d( 2 * channels, 256, 1)\n",
    "\t\t)\n",
    "\n",
    "\tdef residual_block(self, x):\n",
    "\t\treturn (x + self.multiple_blocks(x))\n",
    "\t\n",
    "\tdef forward(self,x):\n",
    "\t\tx = self.ConvA(x)\n",
    "\t\tfor i in range(self.nb_block):\n",
    "\t\t\tx = residual_block(x)\n",
    "\t\tx = self.end(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODAGE DE PIXELRNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RowLSTMCell(nn.Module):\n",
    "    def __init__(self, h, image_size, channel_in, *args, **kargs):\n",
    "        super(RowLSTMCell, self).__init__(*args, **kargs)\n",
    "\n",
    "        self._h = h\n",
    "        self._image_size = image_size\n",
    "        self._channel_in = channel_in\n",
    "        self._num_units = self._h * self._image_size\n",
    "        self._output_size = self._num_units\n",
    "        self._state_size = self._num_units * 2\n",
    "\n",
    "        self.conv_i_s = MaskedConv1d(self._h, 4 * self._h, 3, mask='B', padding='same')\n",
    "        self.conv_s_s = nn.Conv1d(channel_in, 4 * self._h, 3, padding='same')\n",
    "   \n",
    "    def forward(self, inputs, states):\n",
    "        c_previous, h_previous = states\n",
    "\n",
    "\n",
    "\n",
    "        h_previous = h_previous.view(-1, self._h,  self._image_size)\n",
    "        inputs = inputs.view(-1, self._channel_in, self._image_size)\n",
    "\n",
    "        s_s = self.conv_s_s(h_previous) #(batch, 4*h, width)\n",
    "        i_s = self.conv_i_s(inputs) #(batch, 4*h, width)\n",
    "\n",
    "\n",
    "\n",
    "        s_s = s_s.view(-1, 4 * self._num_units) #(batch, 4*h*width)\n",
    "        i_s = i_s.view(-1, 4 * self._num_units) #(batch, 4*h*width)\n",
    "\n",
    "        #print(s_s.size(), i_s.size())\n",
    "\n",
    "        lstm = s_s + i_s\n",
    "\n",
    "        lstm = torch.sigmoid(lstm)\n",
    "\n",
    "        i, g, f, o = torch.split(lstm, (4 * self._num_units)//4, dim=1)\n",
    "\n",
    "        c = f * c_previous + i * g\n",
    "        h = o * torch.tanh(c)\n",
    "\n",
    "        new_state = (c, h)\n",
    "        return h, new_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING FITTED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model_1_Alex.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d85338e3dae5d02b7454e9e0f6d606f697b27b05f28a1716b7a9613db991b1ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
